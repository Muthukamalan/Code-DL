{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75607c-b79b-4019-97f1-e03bb89d9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b703117-1b92-4e9b-bb5f-0cb622dee36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import get_device,set_seed\n",
    "from trainer import Trainer\n",
    "from tester import Tester\n",
    "from dataloader import Cifar10D\n",
    "from transformations import std_transforms,train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d51030-f400-4d13-adfd-f1fdb5f9ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(mix_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33dd9b6e-2660-4cf7-935d-1cb792ab99e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cfc92a-0078-4350-9547-3f81cddf2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self,norm_name:str,dropout_rate:float):\n",
    "        super(Model1,self).__init__()\n",
    "\n",
    "        self.P = nn.MaxPool2d(2,2)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.C1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "        self.C2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,out_channels=12,kernel_size=1,stride=1,padding=1),\n",
    "        )\n",
    "\n",
    "        self.C4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "        self.C5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "        self.C6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        ) \n",
    "        self.c7 = nn.Sequential(\n",
    "           nn.Conv2d(in_channels=32,out_channels=16,kernel_size=1,stride=1,padding=1)\n",
    "        ) \n",
    "\n",
    "        self.C8 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels=16,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "        self.C9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        ) \n",
    "        self.C10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        ) \n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        \n",
    "        self.c11 = nn.Conv2d(in_channels=64,out_channels=10,kernel_size=1,stride=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = self.C1(x); x2 = self.C2(x1)\n",
    "        x = x1+x2     \n",
    "        \n",
    "        x = self.c3(x); \n",
    "        x = self.P(x)  \n",
    "        \n",
    "        x4 = self.C5(self.C4(x)) ; x5 = self.C6(x)\n",
    "        x = x4+x5\n",
    "        \n",
    "        x = self.c7(x)\n",
    "        x = self.P(x)\n",
    "        \n",
    "        x6 = self.C9(self.C8(x));  x7=self.C10(x)\n",
    "        x = x6+x7\n",
    "        x = self.gap(x)\n",
    "        x = self.c11(x)\n",
    "        return F.log_softmax(x.view(-1,10),dim=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ae9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module0(nn.Module):\n",
    "    def __init__(self,norm_name:str,dropout_rate:float=0.01):\n",
    "        super(Module0,self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.norm_name    = norm_name\n",
    "\n",
    "        self.conv1 = self.ConvLayer(in_=3,out_=8,k=3,s=1,p=1).extend(\n",
    "                            self.ConvLayer(in_=8,out_=10,k=3,s=1,p=1)                \n",
    "                        )\n",
    "        \n",
    "        self.trans1 = nn.Sequential(\n",
    "                            nn.MaxPool2d(2,2),\n",
    "                            nn.Conv2d(in_channels=10,out_channels=8,kernel_size=1,stride=1,bias=False)\n",
    "                    )\n",
    "\n",
    "        self.conv2 = self.ConvLayer(in_=8,out_=8,k=3,s=1,p=1).extend(\n",
    "                            self.ConvLayer(in_=8,out_=16,k=3,s=1,p=1)\n",
    "                    )\n",
    "        \n",
    "        self.trans2 = nn.Sequential(\n",
    "                            nn.MaxPool2d(2,2),\n",
    "                            nn.Conv2d(in_channels=16,out_channels=16,kernel_size=1,stride=1,bias=False)\n",
    "                    )\n",
    "        \n",
    "        self.conv3 = self.ConvLayer(in_=16,out_=32,k=3,s=1,p=1).extend(\n",
    "                        self.ConvLayer(in_=32,out_=40,k=3,s=1,p=1)\n",
    "                        ).extend(\n",
    "                                self.ConvLayer(in_=40,out_=64,k=3,s=1,p=1)\n",
    "                        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=10,kernel_size=1,bias=False)\n",
    "        \n",
    "    def ConvLayer(\n",
    "                self,\n",
    "                in_:int,\n",
    "                out_:int,\n",
    "                k:int,\n",
    "                s:int,\n",
    "                p:int,\n",
    "                b=False\n",
    "    )->torch.nn.modules.container.Sequential:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_,out_channels=out_,kernel_size=k,stride=s,padding=p,bias=b),\n",
    "            self.get_norm(out_=out_),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(self.dropout_rate)\n",
    "        )\n",
    "\n",
    "    def get_norm(self,out_):\n",
    "        if self.norm_name=='bn':\n",
    "            return nn.BatchNorm2d(num_features=out_)\n",
    "        else:\n",
    "            raise ValueError('Pass proper normalisation')\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.trans1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.trans2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.conv4(x)\n",
    "        logit = F.log_softmax(x.view(-1,10),dim=1) \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0835e4-5425-4185-b12b-b8b643195955",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = Cifar10D(batch_size=128,is_cuda_available=True)\n",
    "\n",
    "train_loader = cifar10.get_loader(root='../data/',download=False,transform=train_transforms, train=True)\n",
    "test_loader = cifar10.get_loader(root='../data/',download=False,transform=std_transforms, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e099f3-e4cb-4308-b79c-68e5a88a6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Module0(norm_name='bn',dropout_rate=0.1).to(device) #train=50.37 / test=59.57\n",
    "model = Model1(norm_name='bn',dropout_rate=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f16535-0bee-4fc4-838c-b683b113fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot accuracy and loss graphs (INIT)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}\n",
    "\n",
    "def GetCorrectPredCount(pPrediction, pLabels):\n",
    "  return pPrediction.argmax(dim=1).eq(pLabels).sum().item()\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Predict\n",
    "    pred = model(data)\n",
    "\n",
    "    # print(pred.shape)\n",
    "    # print(target.shape)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = criterion(pred, target)\n",
    "    train_loss+=loss.item()\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    correct += GetCorrectPredCount(pred, target)\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Train: Loss={loss.item():0.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "\n",
    "  train_acc.append(100*correct/processed)\n",
    "  train_losses.append(train_loss/len(train_loader))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "            correct += GetCorrectPredCount(output, target)\n",
    "\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d516073f-9717-4d07-97f4-97e873035e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "         Dropout2d-4           [-1, 16, 32, 32]               0\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "              ReLU-7           [-1, 16, 32, 32]               0\n",
      "         Dropout2d-8           [-1, 16, 32, 32]               0\n",
      "            Conv2d-9           [-1, 12, 34, 34]             204\n",
      "        MaxPool2d-10           [-1, 12, 17, 17]               0\n",
      "           Conv2d-11           [-1, 32, 17, 17]           3,488\n",
      "      BatchNorm2d-12           [-1, 32, 17, 17]              64\n",
      "             ReLU-13           [-1, 32, 17, 17]               0\n",
      "        Dropout2d-14           [-1, 32, 17, 17]               0\n",
      "           Conv2d-15           [-1, 32, 17, 17]           9,248\n",
      "      BatchNorm2d-16           [-1, 32, 17, 17]              64\n",
      "             ReLU-17           [-1, 32, 17, 17]               0\n",
      "        Dropout2d-18           [-1, 32, 17, 17]               0\n",
      "           Conv2d-19           [-1, 32, 17, 17]           3,488\n",
      "      BatchNorm2d-20           [-1, 32, 17, 17]              64\n",
      "             ReLU-21           [-1, 32, 17, 17]               0\n",
      "        Dropout2d-22           [-1, 32, 17, 17]               0\n",
      "           Conv2d-23           [-1, 16, 19, 19]             528\n",
      "        MaxPool2d-24             [-1, 16, 9, 9]               0\n",
      "           Conv2d-25             [-1, 64, 9, 9]           9,280\n",
      "      BatchNorm2d-26             [-1, 64, 9, 9]             128\n",
      "             ReLU-27             [-1, 64, 9, 9]               0\n",
      "        Dropout2d-28             [-1, 64, 9, 9]               0\n",
      "           Conv2d-29             [-1, 64, 9, 9]          36,928\n",
      "      BatchNorm2d-30             [-1, 64, 9, 9]             128\n",
      "             ReLU-31             [-1, 64, 9, 9]               0\n",
      "        Dropout2d-32             [-1, 64, 9, 9]               0\n",
      "           Conv2d-33             [-1, 64, 9, 9]           9,280\n",
      "      BatchNorm2d-34             [-1, 64, 9, 9]             128\n",
      "             ReLU-35             [-1, 64, 9, 9]               0\n",
      "        Dropout2d-36             [-1, 64, 9, 9]               0\n",
      "AdaptiveAvgPool2d-37             [-1, 64, 1, 1]               0\n",
      "           Conv2d-38             [-1, 10, 1, 1]             650\n",
      "================================================================\n",
      "Total params: 76,502\n",
      "Trainable params: 76,502\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.51\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 2.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c589b95-788d-468b-b322-1154661357af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.6326 Batch_id=390 Accuracy=26.89: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.6281, Accuracy: 3684/10000 (36.8400%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4587 Batch_id=390 Accuracy=38.98: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4190, Accuracy: 4722/10000 (47.2200%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.6586 Batch_id=390 Accuracy=43.77: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.3555, Accuracy: 5034/10000 (50.3400%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2483 Batch_id=390 Accuracy=47.38: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.2597, Accuracy: 5354/10000 (53.5400%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.4309 Batch_id=390 Accuracy=49.97: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:47<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.1619, Accuracy: 5781/10000 (57.8100%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.9569 Batch_id=390 Accuracy=52.02: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.1912, Accuracy: 5771/10000 (57.7100%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2067 Batch_id=390 Accuracy=55.00: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0313, Accuracy: 6324/10000 (63.2400%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2069 Batch_id=390 Accuracy=56.00: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:45<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0160, Accuracy: 6386/10000 (63.8600%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2040 Batch_id=390 Accuracy=56.17: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0068, Accuracy: 6409/10000 (64.0900%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3439 Batch_id=390 Accuracy=56.39: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0067, Accuracy: 6381/10000 (63.8100%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.1941 Batch_id=390 Accuracy=56.64: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.9857, Accuracy: 6451/10000 (64.5100%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.0831 Batch_id=390 Accuracy=57.02: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.9778, Accuracy: 6503/10000 (65.0300%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.3693 Batch_id=390 Accuracy=57.42: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:46<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.9768, Accuracy: 6548/10000 (65.4800%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=1.2822 Batch_id=390 Accuracy=57.25: 100%|████████████████████████████████████████████████████████████████████| 391/391 [00:44<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.9754, Accuracy: 6550/10000 (65.5000%)\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 0/391 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1, verbose=True)\n",
    "# New Line\n",
    "criterion =  F.nll_loss\n",
    "num_epochs =20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  train(model, device, train_loader, optimizer, criterion)\n",
    "  test(model, device, test_loader, criterion)\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e783982-60f8-43bc-9c89-9ec92205d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
    "\n",
    "axs[0, 0].plot(train_losses)\n",
    "axs[0, 0].set_title(\"Training Loss\")\n",
    "\n",
    "axs[1, 0].plot(train_acc)\n",
    "axs[1, 0].set_title(\"Training Accuracy\")\n",
    "\n",
    "axs[0, 1].plot(test_losses)\n",
    "axs[0, 1].set_title(\"Test Loss\")\n",
    "\n",
    "axs[1, 1].plot(test_acc)\n",
    "axs[1, 1].set_title(\"Test Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa605c-5c7e-4ab5-84af-c474b582fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_egs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24945c74-f9fd-4566-a1b6-b743ae1496a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_egs(train_loader,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61025f23-16cf-4b3b-8563-bb3d01ba579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassified_images(model,test_loader):\n",
    "    model.eval()\n",
    "    images = []\n",
    "    predictions  = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs,targets in test_loader:\n",
    "            inputs  = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _,pred = torch.max(outputs,1)\n",
    "\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i]!=targets[i]:\n",
    "                    images.append(inputs[i])\n",
    "                    predictions.append(pred[i])\n",
    "                    labels.append(targets[i])\n",
    "    return images,predictions,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcb70b-072f-415c-b981-a126a616cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, preds, lbls = get_misclassified_images(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92237b4e-999e-4243-b936-80fac1c1169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misclassified_images( images, predictions, labels, classes):\n",
    "    assert len(images) == len(predictions) == len(labels)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(len(images)):\n",
    "        sub = fig.add_subplot(len(images) // 5, 5, i + 1)\n",
    "        image = images[i]\n",
    "        image = image.T\n",
    "        npimg = image.cpu().numpy().squeeze()\n",
    "        plt.imshow(npimg, cmap=\"gray\")\n",
    "        predicted = classes[predictions[i]]\n",
    "        correct = classes[labels[i]]\n",
    "        sub.set_title(\n",
    "            \"Correct class: {}\\nPredicted class: {}\".format(correct, predicted)\n",
    "        )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb68d7-7dc0-4edb-84f9-2418d26ef33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_misclassified_images(images=imgs[:20],predictions=preds[:20],labels=lbls[:20],classes=cifar10.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6d45b-755d-4e0a-a30a-53bf280309a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
