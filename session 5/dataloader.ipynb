{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WkwH9sfU9RLC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kUBWT2kA-Tm"
      },
      "source": [
        "**1 epoch**: one complete pass of the training dataset through the algorithm\n",
        "\n",
        "**batch_size**: the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you will need.\n",
        "\n",
        "**No of iterations = No of batches**: number of passes, each pass using batch_size number of examples.\n",
        "\n",
        "Example: With 100 training examples and batch size of 20 it will take 5 iterations to complete 1 epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFeJx8YzA-Tm"
      },
      "source": [
        "# Dataloaders (PyTorch)\n",
        "\n",
        "The Dataset retrieves our dataset's features and labels one sample at a time. While training a model, we typically want to\n",
        "\n",
        "1.   Pass samples in “minibatches”\n",
        "2.   Reshuffle the data at every epoch to reduce model overfitting\n",
        "3.   Use Python's multiprocessing to speed up data retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RHffau3A-To"
      },
      "source": [
        "# Sample DataLoader\n",
        "\n",
        "Handles data loading logic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ENf4LWb-MZ5P"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Dataloader will use dataset to create batches, process data etc.\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    # constructor, in this case it contains the data\n",
        "    def __init__(self, xs, ys):\n",
        "        self.input = input\n",
        "        self.target = target\n",
        "\n",
        "    # returns the length of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    # returns the item at index i\n",
        "    def __getitem__(self, i):\n",
        "        return self.input[i], self.target[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD7Lw07mEbft"
      },
      "source": [
        "You want to train a model to learn that the target = 2 x input, and hence created the following dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6rOUn8rM53n",
        "outputId": "41810184-fa96-4b45-b097-91db1edebdd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input values:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "target values:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(4, 8)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We are creating a dummy dataset to test Dataloaders\n",
        "input = list(range(10))\n",
        "target = list(range(0, 20, 2))\n",
        "print('input values: ', input)\n",
        "print('target values: ', target)\n",
        "\n",
        "# Create an instance of MyDataset class\n",
        "dataset = MyDataset(input, target)\n",
        "\n",
        "dataset[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1fO482wRkAb"
      },
      "source": [
        "### Let's look at different ways of creating the Dataloader object using the Dataloader class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q_QDR9FA-To",
        "outputId": "ca9c3c28-759d-4977-d434-d1671e5522b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch of inputs: [0], batch of labels: [0]\n",
            "batch of inputs: [1], batch of labels: [2]\n",
            "batch of inputs: [2], batch of labels: [4]\n",
            "batch of inputs: [3], batch of labels: [6]\n",
            "batch of inputs: [4], batch of labels: [8]\n",
            "batch of inputs: [5], batch of labels: [10]\n",
            "batch of inputs: [6], batch of labels: [12]\n",
            "batch of inputs: [7], batch of labels: [14]\n",
            "batch of inputs: [8], batch of labels: [16]\n",
            "batch of inputs: [9], batch of labels: [18]\n"
          ]
        }
      ],
      "source": [
        "# batch size of 1, so we the size of x and y is 1 and no shuffling\n",
        "for x, y in DataLoader(dataset):\n",
        "    print(f\"batch of inputs: {x.numpy()}, batch of labels: {y.numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klMIFFxPR7qY",
        "outputId": "4a5955f3-6e50-4754-9546-14e381fc1da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch of inputs: [0 1 2 3], batch of labels: [0 2 4 6]\n",
            "batch of inputs: [4 5 6 7], batch of labels: [ 8 10 12 14]\n",
            "batch of inputs: [8 9], batch of labels: [16 18]\n"
          ]
        }
      ],
      "source": [
        "# batch size of 4, so x and y both have a size of 4, no shuffling\n",
        "for x, y in DataLoader(dataset, batch_size=4):\n",
        "    print(f\"batch of inputs: {x.numpy()}, batch of labels: {y.numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHzO_2gLA-To",
        "outputId": "f583efd6-9b0e-4080-dd51-54eafa89dacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch of inputs: tensor([7, 5, 3, 9]), batch of labels: tensor([14, 10,  6, 18])\n",
            "batch of inputs: tensor([6, 4, 0, 8]), batch of labels: tensor([12,  8,  0, 16])\n",
            "batch of inputs: tensor([2, 1]), batch of labels: tensor([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# batch size of 4, so x and y both have a size of 4, random shuffle\n",
        "for x, y in DataLoader(dataset, batch_size=4, shuffle=True):\n",
        "    print(f\"batch of inputs: {x}, batch of labels: {y}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUsk2wl9QZ0e",
        "outputId": "02f8bf1d-ac5b-4a3c-e235-239d3235104c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch of inputs: tensor([4, 9, 0, 6]), batch of labels: tensor([ 8, 18,  0, 12])\n",
            "batch of inputs: tensor([3, 8, 5, 7]), batch of labels: tensor([ 6, 16, 10, 14])\n"
          ]
        }
      ],
      "source": [
        "# batch size of 4, drop the last batch with less than 4 samples\n",
        "for x, y in DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True):\n",
        "    print(f\"batch of inputs: {x}, batch of labels: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the ```num_workers``` to specify how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2 sub processess\n",
        "for x, y in DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True,num_workers=2):\n",
        "    print(f\"batch of inputs: {x}, batch of labels: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use ```pin_memory``` to copy Tensors into device/CUDA pinned memory before returning them -> faster processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x115e6371cd0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True,num_workers=2,pin_memory=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
